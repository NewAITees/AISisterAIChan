# 伺かLLM統合実装ガイド
## LLM出力からさくらスクリプトへの完全変換マニュアル

---

## 目次

1. [概要](#概要)
2. [さくらスクリプト基本構造](#さくらスクリプト基本構造)
3. [文字コード処理](#文字コード処理)
4. [LLM出力のフォーマット制御](#llm出力のフォーマット制御)
5. [遅延・間の制御](#遅延間の制御)
6. [実装アーキテクチャ](#実装アーキテクチャ)
7. [プロンプトエンジニアリング](#プロンプトエンジニアリング)
8. [エラーハンドリング](#エラーハンドリング)
9. [実装例（Python）](#実装例python)
10. [トラブルシューティング](#トラブルシューティング)

---

## 概要

伺か（ukagaka）にLLMを統合する際の最大の課題は、**LLMの自然言語出力をさくらスクリプト形式に適切に変換すること**です。本ガイドでは、以下の要素を網羅的に解説します：

- **さくらスクリプトタグの自動挿入**（話者切替、遅延、改行など）
- **文字コード変換**（UTF-8 ↔ Shift_JIS/Windows-31J）
- **LLM出力の制御**（プロンプトエンジニアリングによる形式統一）
- **自然な会話演出**（タイミング制御とサーフェス切替）

---

## さくらスクリプト基本構造

### 必須タグ一覧

| タグ | 機能 | 使用例 | 備考 |
|------|------|--------|------|
| `\0` | メインキャラ（本体側）の発話 | `\0こんにちは` | デフォルトフォーカス |
| `\1` | サブキャラ（相方側）の発話 | `\1やあ` | 2人目のキャラクター |
| `\p[n]` | n人目のキャラ発話 | `\p[2]`, `\p[3]` | 3人以上の場合 |
| `\n` | 改行（バルーン内） | `こんにちは\nいい天気ですね` | テキスト表示の改行 |
| `\n\n` | 段落区切り | `段落1\n\n段落2` | 視覚的な区切り |
| `\w[n]` | 短時間待機（50ms単位） | `\w3`, `\w9` | n=1～9、50ms×n |
| `\_w[ms]` | ミリ秒単位待機 | `\_w[500]`, `\_w[1000]` | 精密な時間制御 |
| `\s[n]` | サーフェス変更 | `\s[0]`, `\s[10]` | 表情・ポーズ変更 |
| `\i[n]` | アニメーション実行 | `\i[200]` | 指定IDの動作実行 |
| `\e` | スクリプト終了 | `最後の文\e` | 必須の終端タグ |
| `\x` | クリック待ち | `続きは\x次へ` | ユーザー操作待ち |

### 基本会話パターン

```
\0\s[0]ねえねえ、\w5お兄ちゃん！\w8\w8
\1\s[10]なに？\w5
\0\s[1]今日はいい天気だね♪\w8
\e
```

**解説**：
1. メインキャラ（\0）が通常顔（s[0]）で話し始める
2. 「お兄ちゃん！」の後に400ms（w8×50ms）の間
3. サブキャラ（\1）がサーフェス10で応答
4. メインキャラが笑顔（s[1]）に変わり最終発言
5. \eで終了

---

## 文字コード処理

### 文字コードの基礎知識

伺かの標準文字コードは**Shift_JIS（Windows-31J/CP932）**です。一方、現代的なLLM（ChatGPT、Claude等）は**UTF-8**で動作します。この不一致を適切に処理する必要があります。

#### 文字コード比較表

| エンコーディング | 使用場面 | 特徴 | 注意点 |
|----------------|----------|------|--------|
| UTF-8 | LLM API、モダンシステム | 全世界の文字に対応 | 1文字1～4バイト可変長 |
| Shift_JIS | 伺か、レガシーWindows | 日本語専用、1文字1～2バイト | 機種依存文字に注意 |
| Windows-31J (CP932) | Windowsネイティブ | Shift_JISの拡張版 | MSの独自拡張含む |

#### 変換時の問題文字

以下の文字は変換時に特別な注意が必要です：

| 文字 | UTF-8 | Shift_JIS | 対処法 |
|------|-------|-----------|--------|
| ～（波ダッシュ） | U+301C | 0x8160 | 全角チルダ（U+FF5E）に変換推奨 |
| － | U+2212 | 変換不可 | 全角マイナス（U+FF0D）使用 |
| ① | U+2460 | 変換可 | 機種依存文字として扱う |
| 髙（はしごだか） | U+9AD9 | 変換可 | サロゲートペア注意 |
| 濁点付き文字 | 合成文字 | 変換不可 | NFC正規化必須 |

### Python実装例（文字コード変換）

```python
import unicodedata

def safe_encode_to_shiftjis(text: str) -> bytes:
    """
    UTF-8テキストをShift_JIS（Windows-31J）に安全に変換
    
    Args:
        text: UTF-8文字列
        
    Returns:
        Shift_JISバイト列
    """
    # 1. Unicode正規化（合成文字を分解）
    text = unicodedata.normalize('NFC', text)
    
    # 2. 問題文字の事前置換
    replacements = {
        '\u301C': '\uFF5E',  # 波ダッシュ→全角チルダ
        '\u2212': '\uFF0D',  # マイナス記号→全角マイナス
        '\u2015': '\u2014',  # 全角ダッシュ
        '\u2225': '\u2016',  # 並行記号
        '\uFFE0': '\u00A2',  # セント記号
        '\uFFE1': '\u00A3',  # ポンド記号
    }
    
    for utf8_char, sjis_char in replacements.items():
        text = text.replace(utf8_char, sjis_char)
    
    # 3. Windows-31J（cp932）でエンコード
    try:
        return text.encode('cp932', errors='replace')
    except UnicodeEncodeError as e:
        # エラー文字を?に置換して再試行
        print(f"Warning: Character encoding error: {e}")
        return text.encode('cp932', errors='replace')

def decode_from_shiftjis(data: bytes) -> str:
    """
    Shift_JISバイト列をUTF-8文字列にデコード
    
    Args:
        data: Shift_JISバイト列
        
    Returns:
        UTF-8文字列
    """
    try:
        return data.decode('cp932')
    except UnicodeDecodeError:
        # 失敗時はShift_JISでフォールバック
        return data.decode('shift_jis', errors='replace')
```

---

## LLM出力のフォーマット制御

### 問題：生のLLM出力は使えない

LLMが生成する素の出力には以下の問題があります：

❌ **悪い例（生成されたままの出力）**：
```
こんにちは！今日はいい天気ですね。お散歩でも行きませんか？
そうだね、でも僕は今ちょっと忙しいんだ。
じゃあ後でね！
```

この出力には：
- 話者の区別がない
- さくらスクリプトタグがない
- 遅延・間の制御がない
- サーフェス変更指示がない

### 解決策：構造化出力の強制

#### 方法1：JSON形式での出力指示

```python
SYSTEM_PROMPT = """
あなたは「妹AI」として振る舞ってください。
出力は必ず以下のJSON形式で返してください：

{
  "speaker": "0 or 1",  # 0=妹、1=ユーザー（兄）
  "surface": "0-100",   # サーフェスID
  "text": "セリフ本文",
  "emotion": "normal/happy/sad/angry",  # 感情
  "delay_after": 0-2000  # 発話後の待機時間（ミリ秒）
}

複数のセリフがある場合は配列で返してください。
"""

USER_PROMPT = """
ユーザー: {user_input}

上記の入力に対して、妹キャラとして自然に応答してください。
会話の雰囲気に合わせて表情（surface）と感情を設定してください。
"""
```

#### 方法2：カスタムタグでの出力指示

```python
SYSTEM_PROMPT = """
あなたは伺か（デスクトップマスコット）の妹キャラです。

以下の形式で出力してください：
<speak speaker="0" surface="0" delay="500">セリフ内容</speak>

- speaker: 0（妹）または1（ユーザー）
- surface: 表情ID（0=通常、1=笑顔、2=困り顔など）
- delay: 発話後の待機時間（ミリ秒）

例：
<speak speaker="0" surface="1" delay="800">おはよう、お兄ちゃん！</speak>
<speak speaker="1" surface="10" delay="300">おはよう</speak>
<speak speaker="0" surface="0" delay="1000">今日は何するの？</speak>
"""
```

### JSON出力のパース例

```python
import json
import re

def parse_llm_json_output(llm_response: str) -> list[dict]:
    """
    LLMのJSON出力をパースして会話データに変換
    
    Args:
        llm_response: LLMの生のレスポンス
        
    Returns:
        会話データのリスト
    """
    # JSON部分を抽出（```json```で囲まれている場合に対応）
    json_match = re.search(r'```json\s*(\[.*?\])\s*```', llm_response, re.DOTALL)
    if json_match:
        json_str = json_match.group(1)
    else:
        # そのままJSONとして扱う
        json_str = llm_response
    
    try:
        # JSONをパース
        data = json.loads(json_str)
        
        # 単一オブジェクトの場合はリスト化
        if isinstance(data, dict):
            data = [data]
        
        return data
    
    except json.JSONDecodeError as e:
        print(f"Error parsing JSON: {e}")
        # フォールバック：プレーンテキストとして扱う
        return [{
            "speaker": "0",
            "surface": "0",
            "text": llm_response,
            "emotion": "normal",
            "delay_after": 1000
        }]
```

---

## 遅延・間の制御

### 自然な会話リズムの作り方

人間らしい会話には「間（ま）」が不可欠です。以下のガイドラインに従って遅延を挿入します。

#### 遅延タイミングの基準表

| シチュエーション | 遅延時間 | タグ表記 | 用途 |
|----------------|---------|---------|------|
| 文節の区切り | 150-250ms | `\w3` ~ `\w5` | 自然な話し方 |
| 句読点後 | 300-500ms | `\w6` ~ `\_w[500]` | 息継ぎ |
| 考え込む時 | 500-1000ms | `\_w[800]` | 思考中の演出 |
| 感情的な間 | 1000-2000ms | `\_w[1500]` | 驚き、衝撃など |
| 話者交代前 | 200-400ms | `\w4` ~ `\w8` | 自然な切り替え |
| API応答待ち | 1000-3000ms | アニメーション併用 | 処理中表示 |

#### 実装例：自動遅延挿入

```python
import re

def add_natural_delays(text: str) -> str:
    """
    テキストに自然な遅延タグを自動挿入
    
    Args:
        text: プレーンテキスト
        
    Returns:
        遅延タグ付きテキスト
    """
    # 句読点後に遅延挿入
    text = re.sub(r'([。！？])', r'\1\_w[400]', text)
    text = re.sub(r'([、,])', r'\1\w5', text)
    
    # 感嘆詞・間投詞の後に短い間
    text = re.sub(r'(ええと|あの|えっと|うーん)', r'\1\w3', text)
    
    # 三点リーダー（...）には長めの間
    text = re.sub(r'(…{1,3})', r'\1\_w[800]', text)
    
    # 疑問形の前に短い間
    text = re.sub(r'(ね|よね|かな)\?', r'\w3\1?', text)
    
    return text

# 使用例
original = "ええと…そうだね。今日は、お散歩に行こうかな？"
with_delays = add_natural_delays(original)
print(with_delays)
# → "ええと\w3…\_w[800]そうだね。\_w[400]今日は、\w5お散歩に行こうかな？\_w[400]"
```

### 口パクアニメーションとの同期

```python
def sync_with_lipsync(text: str, chars_per_frame: int = 2) -> str:
    """
    口パクアニメと同期する遅延を挿入
    
    Args:
        text: セリフテキスト
        chars_per_frame: 何文字ごとにフレーム送りするか
        
    Returns:
        口パク同期済みテキスト
    """
    result = []
    for i, char in enumerate(text):
        result.append(char)
        # N文字ごとに短い遅延（口パクフレーム送り）
        if (i + 1) % chars_per_frame == 0 and char not in ['\n', '\\']:
            result.append('\\w1')  # 50ms
    
    return ''.join(result)
```

---

## 実装アーキテクチャ

### システム全体構成図

```
┌─────────────────┐
│  ユーザー入力    │
│  (SSPから)      │
└────────┬────────┘
         │
         ▼
┌─────────────────────────┐
│  SHIORI (C#/Python)     │
│  - OnUserInput受信      │
│  - 前処理・文字コード変換│
└────────┬────────────────┘
         │
         ▼
┌─────────────────────────┐
│  LLM API呼び出し        │
│  - プロンプト構築       │
│  - ChatGPT/Claude等     │
│  - 非同期処理           │
└────────┬────────────────┘
         │
         ▼
┌─────────────────────────┐
│  レスポンスパース       │
│  - JSON/XML解析         │
│  - エラーハンドリング   │
└────────┬────────────────┘
         │
         ▼
┌─────────────────────────┐
│  さくらスクリプト生成   │
│  - タグ挿入             │
│  - 遅延制御             │
│  - サーフェス指定       │
│  - 文字コード変換       │
└────────┬────────────────┘
         │
         ▼
┌─────────────────────────┐
│  SSPへ返却              │
│  (Shift_JIS)            │
└─────────────────────────┘
```

### コア変換クラス

```python
from dataclasses import dataclass
from typing import List, Optional
import json

@dataclass
class DialogueLine:
    """会話1行分のデータ"""
    speaker: int  # 0=メイン、1=サブ
    text: str
    surface: int = 0
    emotion: str = "normal"
    delay_after: int = 500  # ミリ秒
    
class SakuraScriptConverter:
    """LLM出力をさくらスクリプトに変換"""
    
    # 感情→サーフェスIDマッピング（カスタマイズ可能）
    EMOTION_SURFACE_MAP = {
        "normal": 0,
        "happy": 1,
        "smile": 1,
        "sad": 2,
        "cry": 3,
        "angry": 4,
        "surprised": 5,
        "shy": 6,
    }
    
    def __init__(self):
        self.last_speaker = 0
        self.last_surface = {0: 0, 1: 10}  # 各キャラの最後のサーフェス
    
    def convert_dialogue_to_script(self, dialogues: List[DialogueLine]) -> str:
        """
        会話データリストをさくらスクリプトに変換
        
        Args:
            dialogues: 会話データのリスト
            
        Returns:
            完全なさくらスクリプト文字列
        """
        script_parts = []
        
        for dialogue in dialogues:
            # 話者切替
            speaker_tag = f"\\{dialogue.speaker}"
            
            # サーフェス変更（前回と異なる場合のみ）
            surface_id = self._get_surface_id(dialogue)
            if surface_id != self.last_surface[dialogue.speaker]:
                surface_tag = f"\\s[{surface_id}]"
                self.last_surface[dialogue.speaker] = surface_id
            else:
                surface_tag = ""
            
            # テキストに自然な遅延を追加
            text_with_delays = add_natural_delays(dialogue.text)
            
            # 発話後の遅延
            delay_tag = f"\\_w[{dialogue.delay_after}]" if dialogue.delay_after > 0 else ""
            
            # 組み立て
            line = f"{speaker_tag}{surface_tag}{text_with_delays}{delay_tag}"
            script_parts.append(line)
            
            self.last_speaker = dialogue.speaker
        
        # 最後に終了タグ
        script = "".join(script_parts) + "\\e"
        
        return script
    
    def _get_surface_id(self, dialogue: DialogueLine) -> int:
        """感情からサーフェスIDを取得"""
        if dialogue.surface > 0:
            return dialogue.surface
        
        emotion = dialogue.emotion.lower()
        return self.EMOTION_SURFACE_MAP.get(emotion, 0)
    
    def parse_llm_json(self, llm_output: str) -> List[DialogueLine]:
        """LLMのJSON出力をDialogueLineのリストに変換"""
        try:
            data = json.loads(llm_output)
            if isinstance(data, dict):
                data = [data]
            
            dialogues = []
            for item in data:
                dialogue = DialogueLine(
                    speaker=int(item.get("speaker", 0)),
                    text=item.get("text", ""),
                    surface=int(item.get("surface", 0)),
                    emotion=item.get("emotion", "normal"),
                    delay_after=int(item.get("delay_after", 500))
                )
                dialogues.append(dialogue)
            
            return dialogues
        
        except (json.JSONDecodeError, ValueError) as e:
            # パース失敗時はプレーンテキストとしてフォールバック
            return [DialogueLine(
                speaker=0,
                text=llm_output,
                emotion="normal"
            )]
```

---

## プロンプトエンジニアリング

### 高品質出力のためのプロンプト設計

#### システムプロンプトのテンプレート

```python
SYSTEM_PROMPT_TEMPLATE = """
あなたは伺か（ukagaka）のデスクトップマスコットキャラクター「{character_name}」です。

## キャラクター設定
- 名前: {character_name}
- 性格: {personality}
- 口調: {speech_style}
- 一人称: {first_person}
- 二人称: {second_person}（ユーザーの呼び方）

## 重要な出力ルール
1. **必ずJSON形式で出力してください**
2. 出力形式の例：
```json
[
  {
    "speaker": 0,
    "text": "こんにちは！",
    "emotion": "happy",
    "delay_after": 800
  },
  {
    "speaker": 1,
    "text": "やあ",
    "emotion": "normal",
    "delay_after": 300
  }
]
```

3. speaker: 0（あなた={character_name}）、1（ユーザー={user_name}）
4. emotion: normal/happy/sad/angry/surprised/shy から選択
5. delay_after: 次の発話までの間（ミリ秒）、通常500-1000推奨
6. text: セリフ本文（改行は不要、自動で処理されます）

## 会話のガイドライン
- 短く自然な会話を心がけてください（1発話15-30文字程度）
- 長文は複数の発話に分割してください
- 感情変化に応じてemotionを変更してください
- ユーザーの発話（speaker=1）を含める場合、簡潔な相槌や応答にしてください

## 禁止事項
- さくらスクリプトタグ（\\0、\\n等）を直接含めないでください
- プレーンテキストで返さず、必ずJSON形式を守ってください
- 長すぎる一文（50文字超）は避けてください
"""

def create_system_prompt(
    character_name: str = "アイちゃん",
    personality: str = "明るく元気な妹キャラ",
    speech_style: str = "です・ます調とタメ口を混ぜた親しみやすい口調",
    first_person: str = "私",
    second_person: str = "お兄ちゃん",
    user_name: str = "お兄ちゃん"
) -> str:
    """システムプロンプトを生成"""
    return SYSTEM_PROMPT_TEMPLATE.format(
        character_name=character_name,
        personality=personality,
        speech_style=speech_style,
        first_person=first_person,
        second_person=second_person,
        user_name=user_name
    )
```

#### ユーザープロンプトの構築

```python
def create_user_prompt(
    user_input: str,
    conversation_history: List[dict] = None,
    context: str = None
) -> str:
    """
    ユーザー入力からLLMへのプロンプトを構築
    
    Args:
        user_input: ユーザーの発言
        conversation_history: 過去の会話履歴
        context: 追加コンテキスト（現在時刻、ユーザー状態など）
        
    Returns:
        完全なユーザープロンプト
    """
    prompt_parts = []
    
    # 会話履歴（最新5ターンのみ）
    if conversation_history:
        prompt_parts.append("## 最近の会話")
        for turn in conversation_history[-5:]:
            speaker = turn.get("speaker", 0)
            text = turn.get("text", "")
            name = "あなた" if speaker == 0 else "ユーザー"
            prompt_parts.append(f"{name}: {text}")
        prompt_parts.append("")
    
    # コンテキスト情報
    if context:
        prompt_parts.append(f"## 現在の状況\n{context}\n")
    
    # ユーザー入力
    prompt_parts.append(f"## ユーザーの新しい発言\nユーザー: {user_input}\n")
    
    # 指示
    prompt_parts.append(
        "上記の発言に対して、あなたのキャラクターとして自然に応答してください。\n"
        "JSON形式で返してください。"
    )
    
    return "\n".join(prompt_parts)
```

### 出力品質向上のテクニック

#### 1. Few-Shot Examplesの活用

```python
FEW_SHOT_EXAMPLES = """
## 良い応答の例

例1：挨拶
ユーザー: おはよう
出力:
```json
[
  {
    "speaker": 0,
    "text": "おはよう、お兄ちゃん！",
    "emotion": "happy",
    "delay_after": 800
  },
  {
    "speaker": 0,
    "text": "よく眠れた？",
    "emotion": "normal",
    "delay_after": 1000
  }
]
```

例2：質問への応答
ユーザー: 今日の天気は？
出力:
```json
[
  {
    "speaker": 0,
    "text": "ええと…",
    "emotion": "normal",
    "delay_after": 500
  },
  {
    "speaker": 0,
    "text": "今日は晴れみたいだよ！",
    "emotion": "happy",
    "delay_after": 800
  },
  {
    "speaker": 0,
    "text": "お散歩日和だね♪",
    "emotion": "smile",
    "delay_after": 1000
  }
]
```
"""
```

#### 2. 出力制約の明示

```python
OUTPUT_CONSTRAINTS = """
## 出力制約（厳守）

✓ 1発話あたり15-30文字を目安に
✓ 合計で3発話まで（長すぎる応答は避ける）
✓ 必ずJSON配列形式
✓ textフィールドに改行文字（\\n）を含めない
✓ delay_afterは200-2000の範囲で設定
✓ emotionは定義された6種類から選択

✗ プレーンテキストで返さない
✗ さくらスクリプトタグを含めない
✗ 1発話が50文字を超える
✗ JSONの構文エラー
"""
```

---

## エラーハンドリング

### 想定されるエラーと対処

```python
class UkagakaLLMError(Exception):
    """伺かLLM統合のベース例外"""
    pass

class LLMAPIError(UkagakaLLMError):
    """LLM API呼び出しエラー"""
    pass

class ParseError(UkagakaLLMError):
    """レスポンスパースエラー"""
    pass

class EncodingError(UkagakaLLMError):
    """文字コード変換エラー"""
    pass

def safe_llm_call(
    api_func,
    *args,
    max_retries: int = 3,
    timeout: float = 10.0,
    fallback_response: str = None,
    **kwargs
) -> str:
    """
    LLM APIを安全に呼び出す（リトライ・タイムアウト付き）
    
    Args:
        api_func: API呼び出し関数
        max_retries: 最大リトライ回数
        timeout: タイムアウト秒数
        fallback_response: エラー時のフォールバック応答
        
    Returns:
        LLMレスポンス文字列
        
    Raises:
        LLMAPIError: リトライ後も失敗した場合
    """
    import time
    from functools import wraps
    
    for attempt in range(max_retries):
        try:
            # タイムアウト付き実行
            response = api_func(*args, **kwargs)
            
            # 空レスポンスチェック
            if not response or not response.strip():
                raise ParseError("Empty response from LLM")
            
            return response
        
        except Exception as e:
            print(f"LLM API call failed (attempt {attempt + 1}/{max_retries}): {e}")
            
            if attempt < max_retries - 1:
                # 指数バックオフ
                wait_time = 2 ** attempt
                time.sleep(wait_time)
            else:
                # 最終試行も失敗
                if fallback_response:
                    print("Using fallback response")
                    return fallback_response
                raise LLMAPIError(f"LLM API failed after {max_retries} attempts") from e

def validate_and_repair_json(json_str: str) -> dict:
    """
    JSONを検証し、可能な限り修復を試みる
    
    Args:
        json_str: JSON文字列
        
    Returns:
        パースされたJSONオブジェクト
        
    Raises:
        ParseError: 修復不可能な場合
    """
    import json
    import re
    
    # 1. Markdownコードブロックの除去
    json_str = re.sub(r'```json\s*', '', json_str)
    json_str = re.sub(r'```\s*$', '', json_str)
    
    # 2. 前後の空白削除
    json_str = json_str.strip()
    
    # 3. パース試行
    try:
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        print(f"JSON parse error: {e}")
        
        # 4. 自動修復試行
        # 4-1. 末尾のカンマ削除
        json_str = re.sub(r',\s*([}\]])', r'\1', json_str)
        
        # 4-2. 閉じ括弧の補完
        open_brackets = json_str.count('[') - json_str.count(']')
        open_braces = json_str.count('{') - json_str.count('}')
        json_str += ']' * open_brackets + '}' * open_braces
        
        # 5. 再パース試行
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            raise ParseError(f"Cannot repair JSON: {json_str[:100]}...")

def create_fallback_dialogue(user_input: str) -> List[DialogueLine]:
    """
    エラー時のフォールバック応答を生成
    
    Args:
        user_input: ユーザー入力
        
    Returns:
        フォールバック用の会話データ
    """
    fallback_messages = [
        "ごめんね、ちょっと考えがまとまらなくて…",
        "えっと、もう一度言ってくれる？",
        "あれ、今なんて言ったの？",
        "ちょっと調子悪いかも…もう一回お願い！",
    ]
    
    import random
    message = random.choice(fallback_messages)
    
    return [DialogueLine(
        speaker=0,
        text=message,
        emotion="sad",
        delay_after=1000
    )]
```

---

## 実装例（Python）

### 完全な統合例

```python
import os
from typing import List, Optional
from openai import OpenAI  # OpenAI APIクライアント

class UkagakaLLMBridge:
    """伺かとLLMを橋渡しするメインクラス"""
    
    def __init__(
        self,
        api_key: str,
        character_name: str = "アイちゃん",
        model: str = "gpt-4-turbo-preview"
    ):
        self.client = OpenAI(api_key=api_key)
        self.model = model
        self.character_name = character_name
        
        self.converter = SakuraScriptConverter()
        self.conversation_history: List[dict] = []
        
        # システムプロンプト生成
        self.system_prompt = create_system_prompt(
            character_name=character_name
        )
    
    def process_user_input(self, user_input: str) -> bytes:
        """
        ユーザー入力を処理してさくらスクリプトを返す
        
        Args:
            user_input: ユーザーの発言（UTF-8）
            
        Returns:
            さくらスクリプト（Shift_JISバイト列）
        """
        try:
            # 1. LLMへのプロンプト構築
            user_prompt = create_user_prompt(
                user_input=user_input,
                conversation_history=self.conversation_history
            )
            
            # 2. LLM API呼び出し
            llm_response = self._call_llm_api(user_prompt)
            
            # 3. レスポンスパース
            dialogues = self._parse_llm_response(llm_response)
            
            # 4. さくらスクリプト生成
            sakura_script = self.converter.convert_dialogue_to_script(dialogues)
            
            # 5. 会話履歴に追加
            self._update_history(user_input, dialogues)
            
            # 6. Shift_JISに変換して返却
            return safe_encode_to_shiftjis(sakura_script)
        
        except Exception as e:
            print(f"Error processing input: {e}")
            # フォールバック応答
            fallback = create_fallback_dialogue(user_input)
            sakura_script = self.converter.convert_dialogue_to_script(fallback)
            return safe_encode_to_shiftjis(sakura_script)
    
    def _call_llm_api(self, user_prompt: str) -> str:
        """LLM APIを呼び出す"""
        def api_call():
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            return response.choices[0].message.content
        
        return safe_llm_call(
            api_call,
            max_retries=3,
            timeout=10.0,
            fallback_response='[{"speaker":0,"text":"ごめんね、今ちょっと考え中…","emotion":"normal","delay_after":1000}]'
        )
    
    def _parse_llm_response(self, llm_response: str) -> List[DialogueLine]:
        """LLMレスポンスをパースしてDialogueLineリストに変換"""
        try:
            # JSONとして解析
            json_data = validate_and_repair_json(llm_response)
            return self.converter.parse_llm_json(json.dumps(json_data))
        
        except ParseError as e:
            print(f"Parse error: {e}")
            # プレーンテキストとして処理
            return [DialogueLine(
                speaker=0,
                text=llm_response[:100],  # 長すぎる場合は切り詰め
                emotion="normal",
                delay_after=1000
            )]
    
    def _update_history(self, user_input: str, dialogues: List[DialogueLine]):
        """会話履歴を更新"""
        # ユーザー入力を追加
        self.conversation_history.append({
            "speaker": 1,
            "text": user_input
        })
        
        # AI応答を追加
        for dialogue in dialogues:
            if dialogue.speaker == 0:  # AIのみ
                self.conversation_history.append({
                    "speaker": dialogue.speaker,
                    "text": dialogue.text
                })
        
        # 履歴を最新20ターンに制限
        if len(self.conversation_history) > 20:
            self.conversation_history = self.conversation_history[-20:]

# 使用例
if __name__ == "__main__":
    # 初期化
    api_key = os.environ.get("OPENAI_API_KEY")
    bridge = UkagakaLLMBridge(api_key=api_key, character_name="アイちゃん")
    
    # テスト
    user_input = "おはよう！"
    sakura_script_bytes = bridge.process_user_input(user_input)
    
    # 結果表示（デバッグ用）
    sakura_script_str = sakura_script_bytes.decode('cp932')
    print(f"Generated script:\n{sakura_script_str}")
```

---

## トラブルシューティング

### よくある問題と解決策

#### 問題1: 文字化けが発生する

**症状**：
- ゴーストの吹き出しに「縺ゅ￥繧�」のような文字が表示される
- 特定の文字（～、①など）だけ化ける

**原因**：
- UTF-8とShift_JISの変換ミス
- Unicode正規化の不足
- 問題文字の未対応

**解決策**：
```python
# 変換前に必ずUnicode正規化
import unicodedata
text = unicodedata.normalize('NFC', text)

# 問題文字を事前置換
text = text.replace('\u301C', '\uFF5E')  # 波ダッシュ

# cp932（Windows-31J）を使用
encoded = text.encode('cp932', errors='replace')
```

#### 問題2: LLMがJSON形式で返してくれない

**症状**：
- プレーンテキストが返ってくる
- マークダウンのコードブロックで囲まれている

**解決策**：
```python
# システムプロンプトで強制
SYSTEM_PROMPT = """
【重要】以下のルールを厳守してください：
1. 必ずJSON形式で出力
2. ```json```のようなマークダウンは不要
3. JSONのみを返す
4. 説明文は一切付けない

出力例（この形式のみ許可）:
[{"speaker":0,"text":"こんにちは","emotion":"happy","delay_after":800}]
"""

# パース時に自動修復
def extract_json(text):
    # コードブロックを除去
    text = re.sub(r'```json\s*', '', text)
    text = re.sub(r'```', '', text)
    # JSON部分のみ抽出
    match = re.search(r'\[.*\]', text, re.DOTALL)
    if match:
        return match.group(0)
    return text
```

#### 問題3: 遅延が効かない・不自然

**症状**：
- 文字が一気に表示される
- 待ち時間が長すぎる/短すぎる

**解決策**：
```python
# SSP側の設定を確認
# - 高速スキップモードになっていないか
# - バルーン設定で待機時間が適切か

# タグの記述を確認
正しい: "\_w[500]"  # アンダースコア + w
間違い: "\w500"     # wの後に数字（これは無効）

# 遅延時間の調整
短い区切り: \w3～\w5  (150-250ms)
句読点:     \_w[400]   (400ms)
長い間:     \_w[1000]  (1秒)
```

#### 問題4: APIタイムアウト・エラー

**症状**：
- ゴーストが固まる
- エラーメッセージが表示される

**解決策**：
```python
# 非同期処理の実装
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def async_llm_call(prompt):
    loop = asyncio.get_event_loop()
    with ThreadPoolExecutor() as pool:
        result = await loop.run_in_executor(
            pool, 
            lambda: call_llm_api(prompt)
        )
    return result

# タイムアウト設定
response = call_llm_api(
    prompt,
    timeout=10.0  # 10秒でタイムアウト
)

# ローディング表示
loading_script = "\\0\s[0]ちょっと待ってね…\\_w[500]\\e"
# → LLM処理中にこれを表示
```

#### 問題5: 会話が不自然・キャラが崩れる

**症状**：
- キャラ設定を無視した発言
- 長すぎる一文
- 感情変化が不自然

**解決策**：
```python
# システムプロンプトを強化
SYSTEM_PROMPT = f"""
【絶対遵守】キャラクター設定
- 一人称: 「私」以外使用禁止
- 語尾: 必ず「～だよ」「～なの」を付ける
- 性格: 明るく元気、少しおっちょこちょい

【禁止事項】
- 丁寧語（です・ます）の連続使用
- 1発話が30文字を超える
- 急な性格変化

【例】
良い: "ねえねえ、今日は何するの？"
悪い: "本日はいかがお過ごしでしょうか。"
"""

# Few-Shot Learningの追加
examples = [
    {"user": "おはよう", "assistant": "おはよー！よく寝れた？"},
    {"user": "疲れた...", "assistant": "大丈夫？ちょっと休む？"}
]
```

---

## まとめ

### チェックリスト

実装時に確認すべき項目：

- [ ] 文字コード変換（UTF-8 ↔ Shift_JIS）が正しく動作
- [ ] LLMのJSON出力が安定している
- [ ] さくらスクリプトタグが適切に挿入されている
- [ ] 遅延・間のタイミングが自然
- [ ] エラーハンドリングが実装されている
- [ ] APIキーが安全に管理されている
- [ ] 会話履歴が適切に保持されている
- [ ] キャラクター性が維持されている
- [ ] パフォーマンスが許容範囲（応答3秒以内）
- [ ] ログ・デバッグ機能が実装されている

### 推奨開発フロー

1. **プロトタイプ作成**（1-2日）
   - 基本的なLLM呼び出し
   - JSON形式の出力確認
   - 簡単な変換ロジック

2. **文字コード対応**（半日）
   - Shift_JIS変換実装
   - 問題文字の対処
   - テストケース作成

3. **スクリプト生成強化**（1-2日）
   - 遅延タグ自動挿入
   - サーフェス制御
   - 自然な会話リズム

4. **エラーハンドリング**（1日）
   - リトライロジック
   - フォールバック応答
   - ログ機能

5. **チューニング**（継続的）
   - プロンプト改善
   - 応答速度最適化
   - キャラクター性調整

### 参考資料

- **UKADOC Project**: https://ukagakadreamteam.github.io/ukadoc/
- **SSP公式**: https://ssp.shillest.net/
- **AI妹アイちゃん（実装例）**: https://github.com/manju-summoner/AISisterAIChan
- **OpenAI API ドキュメント**: https://platform.openai.com/docs
- **文字コード詳細**: https://www.unicode.org/

---

**改訂履歴**
- v1.0 (2026-01-06): 初版作成

**ライセンス**
本ドキュメントはCC BY 4.0で公開されています。